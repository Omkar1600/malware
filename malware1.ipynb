{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a05fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b474157",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('D:\\data\\CSV\\Dataset10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89ae54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>md5</th>\n",
       "      <th>Machine</th>\n",
       "      <th>SizeOfOptionalHeader</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>MajorLinkerVersion</th>\n",
       "      <th>MinorLinkerVersion</th>\n",
       "      <th>SizeOfCode</th>\n",
       "      <th>SizeOfInitializedData</th>\n",
       "      <th>SizeOfUninitializedData</th>\n",
       "      <th>...</th>\n",
       "      <th>ResourcesNb</th>\n",
       "      <th>ResourcesMeanEntropy</th>\n",
       "      <th>ResourcesMinEntropy</th>\n",
       "      <th>ResourcesMaxEntropy</th>\n",
       "      <th>ResourcesMeanSize</th>\n",
       "      <th>ResourcesMinSize</th>\n",
       "      <th>ResourcesMaxSize</th>\n",
       "      <th>LoadConfigurationSize</th>\n",
       "      <th>VersionInformationSize</th>\n",
       "      <th>legitimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memtest.exe</td>\n",
       "      <td>631ea355665f28d4707448e442fbf5b8</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>361984</td>\n",
       "      <td>115712</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.262823</td>\n",
       "      <td>2.568844</td>\n",
       "      <td>3.537939</td>\n",
       "      <td>8797.00000</td>\n",
       "      <td>216</td>\n",
       "      <td>18032</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ose.exe</td>\n",
       "      <td>9d10f99a6712e28f8acd5641e3a7ea6b</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>3330</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>130560</td>\n",
       "      <td>19968</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4.250461</td>\n",
       "      <td>3.420744</td>\n",
       "      <td>5.080177</td>\n",
       "      <td>837.00000</td>\n",
       "      <td>518</td>\n",
       "      <td>1156</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setup.exe</td>\n",
       "      <td>4d92f518527353c0db88a70fddcfd390</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>3330</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>517120</td>\n",
       "      <td>621568</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4.426324</td>\n",
       "      <td>2.846449</td>\n",
       "      <td>5.271813</td>\n",
       "      <td>31102.27273</td>\n",
       "      <td>104</td>\n",
       "      <td>270376</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DW20.EXE</td>\n",
       "      <td>a41e524f8d45f0074fd07805ff0c9b12</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>585728</td>\n",
       "      <td>369152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4.364291</td>\n",
       "      <td>2.669314</td>\n",
       "      <td>6.400720</td>\n",
       "      <td>1457.00000</td>\n",
       "      <td>90</td>\n",
       "      <td>4264</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dwtrig20.exe</td>\n",
       "      <td>c87e561258f2f8650cef999bf643a731</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>294912</td>\n",
       "      <td>247296</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4.306100</td>\n",
       "      <td>3.421598</td>\n",
       "      <td>5.190603</td>\n",
       "      <td>1074.50000</td>\n",
       "      <td>849</td>\n",
       "      <td>1300</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name                               md5  Machine  \\\n",
       "0   memtest.exe  631ea355665f28d4707448e442fbf5b8      332   \n",
       "1       ose.exe  9d10f99a6712e28f8acd5641e3a7ea6b      332   \n",
       "2     setup.exe  4d92f518527353c0db88a70fddcfd390      332   \n",
       "3      DW20.EXE  a41e524f8d45f0074fd07805ff0c9b12      332   \n",
       "4  dwtrig20.exe  c87e561258f2f8650cef999bf643a731      332   \n",
       "\n",
       "   SizeOfOptionalHeader  Characteristics  MajorLinkerVersion  \\\n",
       "0                   224              258                   9   \n",
       "1                   224             3330                   9   \n",
       "2                   224             3330                   9   \n",
       "3                   224              258                   9   \n",
       "4                   224              258                   9   \n",
       "\n",
       "   MinorLinkerVersion  SizeOfCode  SizeOfInitializedData  \\\n",
       "0                   0      361984                 115712   \n",
       "1                   0      130560                  19968   \n",
       "2                   0      517120                 621568   \n",
       "3                   0      585728                 369152   \n",
       "4                   0      294912                 247296   \n",
       "\n",
       "   SizeOfUninitializedData  ...  ResourcesNb  ResourcesMeanEntropy  \\\n",
       "0                        0  ...            4              3.262823   \n",
       "1                        0  ...            2              4.250461   \n",
       "2                        0  ...           11              4.426324   \n",
       "3                        0  ...           10              4.364291   \n",
       "4                        0  ...            2              4.306100   \n",
       "\n",
       "   ResourcesMinEntropy  ResourcesMaxEntropy  ResourcesMeanSize  \\\n",
       "0             2.568844             3.537939         8797.00000   \n",
       "1             3.420744             5.080177          837.00000   \n",
       "2             2.846449             5.271813        31102.27273   \n",
       "3             2.669314             6.400720         1457.00000   \n",
       "4             3.421598             5.190603         1074.50000   \n",
       "\n",
       "   ResourcesMinSize  ResourcesMaxSize  LoadConfigurationSize  \\\n",
       "0               216             18032                      0   \n",
       "1               518              1156                     72   \n",
       "2               104            270376                     72   \n",
       "3                90              4264                     72   \n",
       "4               849              1300                     72   \n",
       "\n",
       "   VersionInformationSize  legitimate  \n",
       "0                      16           1  \n",
       "1                      18           1  \n",
       "2                      18           1  \n",
       "3                      18           1  \n",
       "4                      18           1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b26ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['Name','md5','legitimate'],axis=1).values\n",
    "y = dataset['legitimate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6418a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble as ek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "extratrees = ek.ExtraTreesClassifier().fit(X,y)\n",
    "model = SelectFromModel(extratrees, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nbfeatures = X_new.shape[1]\n",
    "nbfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c767a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8522c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 DllCharacteristics (0.141264)\n",
      "2 Characteristics (0.115059)\n",
      "3 Machine (0.106138)\n",
      "4 Subsystem (0.078601)\n",
      "5 VersionInformationSize (0.063941)\n",
      "6 ImageBase (0.053125)\n",
      "7 SizeOfOptionalHeader (0.050138)\n",
      "8 MajorSubsystemVersion (0.049761)\n",
      "9 SectionsMaxEntropy (0.037846)\n",
      "10 ResourcesMaxEntropy (0.036534)\n",
      "11 ResourcesMinEntropy (0.035373)\n",
      "12 SectionsMinEntropy (0.021783)\n",
      "13 MajorOperatingSystemVersion (0.021042)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "index = np.argsort(extratrees.feature_importances_)[::-1][:nbfeatures]\n",
    "for f in range(nbfeatures):\n",
    "    print(\"%d %s (%f)\" % (f + 1, dataset.columns[2+index[f]], extratrees.feature_importances_[index[f]]))\n",
    "    features.append(dataset.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bffe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest : 0.995001810938066 \n",
      "DecisionTree : 0.9912712785222746 \n",
      "GradientBoosting : 0.9891705903658095 \n",
      "GNB : 0.6986599058312206 \n",
      "LinearRegression : 0.5961603652211285 \n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble as ek\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = { \"RandomForest\":ek.RandomForestClassifier(n_estimators=50),\n",
    "        \"DecisionTree\":tree.DecisionTreeClassifier(max_depth=10),    \n",
    "         \"GradientBoosting\":ek.GradientBoostingClassifier(n_estimators=50),\n",
    "         \"GNB\":GaussianNB(),\n",
    "         \"LinearRegression\":LinearRegression()   \n",
    "}\n",
    "results = {}\n",
    "for algo in model:\n",
    "    clf = model[algo]\n",
    "    clf.fit(X_train,y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    print (\"%s : %s \" %(algo, score))\n",
    "    results[algo] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bcc317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForest'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = max(results, key=results.get)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f8427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "joblib.dump(model[best_model],'classifier.pkl')\n",
    "open('features.pkl','wb').write(pickle.dumps(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63af7670",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    171\u001b[0m clf \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    172\u001b[0m features \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 173\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m pe_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x:data[x], features)\n\u001b[0;32m    176\u001b[0m res\u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict([pe_features])[\u001b[38;5;241m0\u001b[39m]    \n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mextract_infos\u001b[1;34m(fpath)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_infos\u001b[39m(fpath):\n\u001b[0;32m     67\u001b[0m     res \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 68\u001b[0m     pe \u001b[38;5;241m=\u001b[39m \u001b[43mpefile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMachine\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mFILE_HEADER\u001b[38;5;241m.\u001b[39mMachine\n\u001b[0;32m     70\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSizeOfOptionalHeader\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mFILE_HEADER\u001b[38;5;241m.\u001b[39mSizeOfOptionalHeader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pefile.py:2777\u001b[0m, in \u001b[0;36mPE.__init__\u001b[1;34m(self, name, data, fast_load, max_symbol_exports, max_repeated_symbol)\u001b[0m\n\u001b[0;32m   2775\u001b[0m fast_load \u001b[38;5;241m=\u001b[39m fast_load \u001b[38;5;28;01mif\u001b[39;00m fast_load \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfast_load\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2776\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2777\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__parse__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_load\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   2779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pefile.py:2830\u001b[0m, in \u001b[0;36mPE.__parse__\u001b[1;34m(self, fname, data, fast_load)\u001b[0m\n\u001b[0;32m   2823\u001b[0m \u001b[38;5;124;03m\"\"\"Parse a Portable Executable file.\u001b[39;00m\n\u001b[0;32m   2824\u001b[0m \n\u001b[0;32m   2825\u001b[0m \u001b[38;5;124;03mLoads a PE file, parsing all its structures and making them available\u001b[39;00m\n\u001b[0;32m   2826\u001b[0m \u001b[38;5;124;03mthrough the instance's attributes.\u001b[39;00m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2830\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2831\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stat\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2832\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PEFormatError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: '-f'"
     ]
    }
   ],
   "source": [
    "import pefile\n",
    "import os\n",
    "import array\n",
    "import math\n",
    "import pickle\n",
    "import joblib\n",
    "import sys\n",
    "import argparse\n",
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0]*256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x*math.log(p_x, 2)\n",
    "\n",
    "    return \n",
    "\n",
    "def get_resources(pe):\n",
    "    \"\"\"Extract resources :\n",
    "    [entropy, size]\"\"\"\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources\n",
    "\n",
    "def get_version_info(pe):\n",
    "    \"\"\"Return version infos\"\"\"\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "          res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "          res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "          res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "          res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "          res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "          res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "          res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n",
    "\n",
    "#extract the info for a given file\n",
    "def extract_infos(fpath):\n",
    "    res = {}\n",
    "    pe = pefile.PE(fpath)\n",
    "    res['Machine'] = pe.FILE_HEADER.Machine\n",
    "    res['SizeOfOptionalHeader'] = pe.FILE_HEADER.SizeOfOptionalHeader\n",
    "    res['Characteristics'] = pe.FILE_HEADER.Characteristics\n",
    "    res['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion\n",
    "    res['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion\n",
    "    res['SizeOfCode'] = pe.OPTIONAL_HEADER.SizeOfCode\n",
    "    res['SizeOfInitializedData'] = pe.OPTIONAL_HEADER.SizeOfInitializedData\n",
    "    res['SizeOfUninitializedData'] = pe.OPTIONAL_HEADER.SizeOfUninitializedData\n",
    "    res['AddressOfEntryPoint'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint\n",
    "    res['BaseOfCode'] = pe.OPTIONAL_HEADER.BaseOfCode\n",
    "    try:\n",
    "        res['BaseOfData'] = pe.OPTIONAL_HEADER.BaseOfData\n",
    "    except AttributeError:\n",
    "        res['BaseOfData'] = 0\n",
    "    res['ImageBase'] = pe.OPTIONAL_HEADER.ImageBase\n",
    "    res['SectionAlignment'] = pe.OPTIONAL_HEADER.SectionAlignment\n",
    "    res['FileAlignment'] = pe.OPTIONAL_HEADER.FileAlignment\n",
    "    res['MajorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion\n",
    "    res['MinorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion\n",
    "    res['MajorImageVersion'] = pe.OPTIONAL_HEADER.MajorImageVersion\n",
    "    res['MinorImageVersion'] = pe.OPTIONAL_HEADER.MinorImageVersion\n",
    "    res['MajorSubsystemVersion'] = pe.OPTIONAL_HEADER.MajorSubsystemVersion\n",
    "    res['MinorSubsystemVersion'] = pe.OPTIONAL_HEADER.MinorSubsystemVersion\n",
    "    res['SizeOfImage'] = pe.OPTIONAL_HEADER.SizeOfImage\n",
    "    res['SizeOfHeaders'] = pe.OPTIONAL_HEADER.SizeOfHeaders\n",
    "    res['CheckSum'] = pe.OPTIONAL_HEADER.CheckSum\n",
    "    res['Subsystem'] = pe.OPTIONAL_HEADER.Subsystem\n",
    "    res['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics\n",
    "    res['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve\n",
    "    res['SizeOfStackCommit'] = pe.OPTIONAL_HEADER.SizeOfStackCommit\n",
    "    res['SizeOfHeapReserve'] = pe.OPTIONAL_HEADER.SizeOfHeapReserve\n",
    "    res['SizeOfHeapCommit'] = pe.OPTIONAL_HEADER.SizeOfHeapCommit\n",
    "    res['LoaderFlags'] = pe.OPTIONAL_HEADER.LoaderFlags\n",
    "    res['NumberOfRvaAndSizes'] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes\n",
    "    res['SectionsNb'] = len(pe.sections)\n",
    "    entropy = map(lambda x:x.get_entropy(), pe.sections)\n",
    "    res['SectionsMeanEntropy'] = sum(entropy)/float(len(entropy))\n",
    "    res['SectionsMinEntropy'] = min(entropy)\n",
    "    res['SectionsMaxEntropy'] = max(entropy)\n",
    "    raw_sizes = map(lambda x:x.SizeOfRawData, pe.sections)\n",
    "    res['SectionsMeanRawsize'] = sum(raw_sizes)/float(len(raw_sizes))\n",
    "    res['SectionsMinRawsize'] = min(raw_sizes)\n",
    "    res['SectionsMaxRawsize'] = max(raw_sizes)\n",
    "    virtual_sizes = map(lambda x:x.Misc_VirtualSize, pe.sections)\n",
    "    res['SectionsMeanVirtualsize'] = sum(virtual_sizes)/float(len(virtual_sizes))\n",
    "    res['SectionsMinVirtualsize'] = min(virtual_sizes)\n",
    "    res['SectionMaxVirtualsize'] = max(virtual_sizes)\n",
    "\n",
    "    #Imports\n",
    "    try:\n",
    "        res['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT)\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res['ImportsNb'] = len(imports)\n",
    "        res['ImportsNbOrdinal'] = len(filter(lambda x:x.name is None, imports))\n",
    "    except AttributeError:\n",
    "        res['ImportsNbDLL'] = 0\n",
    "        res['ImportsNb'] = 0\n",
    "        res['ImportsNbOrdinal'] = 0\n",
    "\n",
    "    #Exports\n",
    "    try:\n",
    "        res['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res['ExportNb'] = 0\n",
    "    #Resources\n",
    "    resources= get_resources(pe)\n",
    "    res['ResourcesNb'] = len(resources)\n",
    "    if len(resources)> 0:\n",
    "        entropy = map(lambda x:x[0], resources)\n",
    "        res['ResourcesMeanEntropy'] = sum(entropy)/float(len(entropy))\n",
    "        res['ResourcesMinEntropy'] = min(entropy)\n",
    "        res['ResourcesMaxEntropy'] = max(entropy)\n",
    "        sizes = map(lambda x:x[1], resources)\n",
    "        res['ResourcesMeanSize'] = sum(sizes)/float(len(sizes))\n",
    "        res['ResourcesMinSize'] = min(sizes)\n",
    "        res['ResourcesMaxSize'] = max(sizes)\n",
    "    else:\n",
    "        res['ResourcesNb'] = 0\n",
    "        res['ResourcesMeanEntropy'] = 0\n",
    "        res['ResourcesMinEntropy'] = 0\n",
    "        res['ResourcesMaxEntropy'] = 0\n",
    "        res['ResourcesMeanSize'] = 0\n",
    "        res['ResourcesMinSize'] = 0\n",
    "        res['ResourcesMaxSize'] = 0\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res['LoadConfigurationSize'] = pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size\n",
    "    except AttributeError:\n",
    "        res['LoadConfigurationSize'] = 0\n",
    "\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res['VersionInformationSize'] = len(version_infos.keys())\n",
    "    except AttributeError:\n",
    "        res['VersionInformationSize'] = 0\n",
    "    return res\n",
    "if __name__ == '__main__':\n",
    "\t\n",
    "    clf = joblib.load('classifier.pkl')\n",
    "    features = pickle.loads(open(os.path.join('features.pkl'),'rb').read())\n",
    "    data = extract_infos(sys.argv[1])\n",
    "    pe_features = map(lambda x:data[x], features)\n",
    "\n",
    "    res= clf.predict([pe_features])[0]    \n",
    "    print ('The file %s is %s' % (os.path.basename(sys.argv[1]),['malicious', 'legitimate'][res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58428222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% Load test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff300f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run test.py \"C:\\Users\\LENOVO\\Downloads\\\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
